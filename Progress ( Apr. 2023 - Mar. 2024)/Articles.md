## Contents
このファイルでは、これまでに読んだ論文の紹介を行っていきます。
記事の充実具合は、私の関心の高さと相関があります。

### メタ学習関連
メタ学習とは「learning to learn」の標語の下、他ドメインの学習のアルゴリズムを学ぶことで、少量データしかないターゲットドメインの学習を円滑に行う学習方法です。
正直、転移学習との完全な違いはよくわからん。
~~いうより、MAMLにしろNPにしろアルゴリズムそのものを学んでいるわけではなくないか...? ~~
理解。例えばMAMLでいえば学習の目的は最適な初期パラメタを決定する。（これはつまり多くのタスクに適した内部表現を構築することに対応する。
#### Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
(url: https://arxiv.org/abs/1703.03400 )
 meta-learningの基本的なアルゴリズムとなったMAMLが初めて提案された論文。
 簡単に話すと、様々なドメインの最適解に近い初期値を探すことで、ターゲットドメインのデータが非常に少なくてもそこそこ良い性能を出すことができるらしい。
 Torchでの実装を早めにする。
 
 #### On First-Order Meta-Learning Algorithms
 (url: https://arxiv.org/abs/1803.02999 )
 さっきのMAMLは、勾配の勾配を計算する必要があり、明らかに計算量が多すぎる（一次の勾配すらbackpropagationとかの工夫が必要なわけですからね...)
 そこで、MAMLを近似する手法についても研究が行われており、FORMALと呼ばれる一次近似手法をさらに改良したReptileと呼ばれるアルゴリズムについての解説がなされている。
 それはそれとして、非常にイントロなどでメタ学習に関する記事が良質すぎる。さすがopenAI
